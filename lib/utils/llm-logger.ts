/**
 * LLM Logger - Prominently logs all LLM API calls
 * Shows RED NEON SIGNS in console for every LLM operation
 */

import { permanentLogger } from './permanent-logger'

export interface LLMCallLog {
  timestamp: Date
  requestId: string
  sessionId?: string
  phase: string
  method: string
  model: string
  prompt: {
    system?: string
    user: string
    tokens?: number
  }
  response?: {
    content?: string
    tokens?: number
    reasoningTokens?: number
  }
  cost: {
    input: number
    output: number
    total: number
    currency: 'USD'
  }
  duration?: number
  rateLimitInfo?: {
    remaining: number
    reset: Date
  }
  error?: {
    code: string
    message: string
    retryAfter?: number
  }
}

export class LLMLogger {
  private static instance: LLMLogger
  private callCount = 0
  private totalCost = 0
  
  static getInstance(): LLMLogger {
    if (!this.instance) {
      this.instance = new LLMLogger()
    }
    return this.instance
  }

  /**
   * Log an LLM call with PROMINENT RED DISPLAY
   */
  static logCall(params: {
    model: string
    phase: string
    purpose: string
    tokens?: { input: number; output: number }
    cost: number
    sessionId?: string
  }) {
    const instance = this.getInstance()
    instance.callCount++
    instance.totalCost += params.cost
    
    const message = `
ğŸ”´ğŸ”´ğŸ”´ LLM API CALL DETECTED ğŸ”´ğŸ”´ğŸ”´
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ Phase: ${params.phase}
ğŸ¤– Model: ${params.model}
ğŸ“ Purpose: ${params.purpose}
ğŸ“Š Tokens: ${params.tokens?.input || 0} in / ${params.tokens?.output || 0} out
ğŸ’° Cost: $${params.cost.toFixed(4)} USD
ğŸ“ˆ Total Calls: ${instance.callCount}
ğŸ’¸ Total Cost: $${instance.totalCost.toFixed(4)} USD
â° Time: ${new Date().toISOString()}
${params.sessionId ? `ğŸ”— Session: ${params.sessionId}` : ''}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `
    
    // Console with red background - MOST VISIBLE
    if (typeof window === 'undefined') {
      // Server-side: Use ANSI codes
      console.log('\x1b[41m\x1b[37m%s\x1b[0m', message)
    } else {
      // Client-side: Use CSS styling
      console.log(
        '%c' + message,
        'background: #ff0000; color: #ffffff; font-weight: bold; font-size: 14px; padding: 10px;'
      )
    }
    
    // Also log normally for records
    console.log('ğŸš¨ LLM CALL:', params)
    
    // Persistent log
    permanentLogger.info('LLM_CALL', 'API Call Made', { ...params})
    
    // Broadcast to UI if available
    if (typeof window !== 'undefined') {
      window.dispatchEvent(new CustomEvent('llm-call', { detail: params }))
    }
  }
  
  /**
   * Log rate limit status
   */
  static logRateLimit(model: string, remaining: number, reset: Date) {
    const warning = remaining < 50
    const critical = remaining < 10
    
    const message = `
${critical ? 'ğŸš¨ğŸš¨ğŸš¨' : warning ? 'âš ï¸âš ï¸âš ï¸' : 'ğŸ“Š'} RATE LIMIT STATUS: ${model}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Remaining: ${remaining}/500 RPM
Resets: ${reset.toISOString()}
${critical ? 'ğŸš¨ CRITICAL - STOP ALL REQUESTS!' : warning ? 'âš ï¸ WARNING - SLOW DOWN!' : 'âœ… Within limits'}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `
    
    if (critical) {
      // CRITICAL - Red background
      console.log('\x1b[41m\x1b[37m%s\x1b[0m', message)
    } else if (warning) {
      // WARNING - Yellow
      console.log('\x1b[33m%s\x1b[0m', message)
    } else {
      // OK - Normal
      console.log(message)
    }
    
    permanentLogger.info('RATE_LIMIT', `Rate limit status for ${model}`, {
      model,
      remaining,
      reset,
      warning,
      critical
    })
  }
  
  /**
   * Log LLM operation starting (warning before it happens)
   */
  static logLLMOperationStarting(params: {
    phase: string
    operation: string
    estimatedCost: number
    willUseLLM: boolean
  }) {
    if (!params.willUseLLM) return
    
    const message = `
âš ï¸âš ï¸âš ï¸ LLM OPERATION STARTING âš ï¸âš ï¸âš ï¸
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ Phase: ${params.phase}
ğŸ¯ Operation: ${params.operation}
ğŸ’° Estimated Cost: $${params.estimatedCost.toFixed(4)} USD
â±ï¸ Starting in: 3 seconds...
ğŸ›‘ Press Ctrl+C to abort
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `
    
    // Yellow warning
    if (typeof window === 'undefined') {
      console.log('\x1b[43m\x1b[30m%s\x1b[0m', message)
    } else {
      console.log(
        '%c' + message,
        'background: #ffcc00; color: #000000; font-weight: bold; font-size: 13px; padding: 8px;'
      )
    }
    
    permanentLogger.info('LLM_WARNING', 'LLM Operation Starting', { ...params})
  }
  
  /**
   * Log error with LLM call
   */
  static logError(error: any, context: {
    model: string
    phase: string
    attemptNumber?: number
  }) {
    const message = `
âŒâŒâŒ LLM CALL FAILED âŒâŒâŒ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ“ Phase: ${context.phase}
ğŸ¤– Model: ${context.model}
${context.attemptNumber ? `ğŸ”„ Attempt: ${context.attemptNumber}` : ''}
âŒ Error: ${error.message || error}
${error.code ? `ğŸ“ Code: ${error.code}` : ''}
${error.status === 429 ? 'â³ Rate Limited - Will Retry' : ''}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `
    
    console.error('\x1b[41m\x1b[37m%s\x1b[0m', message)
    
    permanentLogger.info('LLM_ERROR', 'LLM Call Failed', {
      ...context,
      error: error.message || error,
      code: error.code,
      status: error.status
    })
  }
  
  /**
   * Log phase completion
   */
  static logPhaseComplete(phase: string, metrics: {
    duration: number
    llmCalls: number
    cost: number
    success: boolean
  }) {
    const message = `
${metrics.success ? 'âœ…' : 'âŒ'} PHASE COMPLETED: ${phase}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â±ï¸ Duration: ${(metrics.duration / 1000).toFixed(2)}s
ğŸ¤– LLM Calls: ${metrics.llmCalls}
ğŸ’° Cost: $${metrics.cost.toFixed(4)} USD
ğŸ“Š Status: ${metrics.success ? 'SUCCESS' : 'FAILED'}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    `
    
    const color = metrics.success ? '\x1b[42m\x1b[37m' : '\x1b[41m\x1b[37m'
    console.log(`${color}%s\x1b[0m`, message)
    
    permanentLogger.info('PHASE_COMPLETE', `Phase ${phase} completed`, metrics)
  }
  
  /**
   * Get summary of all LLM calls
   */
  static getSummary() {
    const instance = this.getInstance()
    return {
      totalCalls: instance.callCount,
      totalCost: instance.totalCost,
      averageCost: instance.callCount > 0 ? instance.totalCost / instance.callCount : 0
    }
  }
  
  /**
   * Reset counters
   */
  static reset() {
    const instance = this.getInstance()
    instance.callCount = 0
    instance.totalCost = 0
  }
}

// Export convenience functions
export const logLLMCall = LLMLogger.logCall.bind(LLMLogger)
export const logRateLimit = LLMLogger.logRateLimit.bind(LLMLogger)
export const logLLMWarning = LLMLogger.logLLMOperationStarting.bind(LLMLogger)
export const logLLMError = LLMLogger.logError.bind(LLMLogger)
export const logPhaseComplete = LLMLogger.logPhaseComplete.bind(LLMLogger)