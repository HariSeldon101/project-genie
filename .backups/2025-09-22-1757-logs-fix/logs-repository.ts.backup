/**
 * Logs Repository - Database Access Layer
 *
 * ARCHITECTURE PATTERN: Repository Pattern with Clean Architecture
 *
 * This repository handles ALL database operations for permanent_logs table.
 * It receives domain-specific query parameters that map directly
 * to database operations.
 *
 * IMPORTANT: Repository expects NESTED filter structure
 * This differs from the flat API structure intentionally:
 * - API uses flat structure for REST simplicity
 * - Repository uses nested structure for query organization
 * - Service layer transforms between them
 *
 * WHY DIFFERENT FROM API?
 * - Database queries may need additional filters not exposed to API
 * - Internal structure can evolve independently from public API
 * - Allows complex query composition without API changes
 * - Follows clean architecture principle of layer separation
 *
 * DATA FLOW:
 * API (LogsApiDto) -> Service (transforms) -> Repository (LogsQueryParams)
 *
 * Now using type-safe column selection to prevent runtime errors
 * from column name mismatches (e.g., 'level' vs 'log_level')
 *
 * @module logs-repository
 */

import { BaseRepository } from './base-repository'
import { permanentLogger } from '@/lib/utils/permanent-logger'
import { typedColumns, typedColumn, typedSelect } from './type-safe-query'
import type { Database } from '@/lib/database.types'

// Define types based on database schema
type LogEntry = Database['public']['Tables']['permanent_logs']['Row']
type LogInsert = Database['public']['Tables']['permanent_logs']['Insert']
type LogUpdate = Database['public']['Tables']['permanent_logs']['Update']
type LogsTable = Database['public']['Tables']['permanent_logs']

/**
 * Filter structure for database queries
 * INTERNAL USE: More comprehensive than what's exposed to API
 * Includes fields like action, date ranges that may not be in API
 */
export interface LogFilters {
  level?: string | string[]
  category?: string | string[]
  action?: string | string[]    // Not exposed to API currently
  startDate?: string             // Not exposed to API currently
  endDate?: string               // Not exposed to API currently
  search?: string
}

/**
 * Query parameters for repository operations
 * INTERNAL USE: Not exposed to API directly
 *
 * NESTED STRUCTURE: Filters are grouped in a 'filters' object
 * This differs from LogsApiDto which has flat structure
 * Service layer transforms between them
 */
export interface LogsQueryParams {
  page?: number
  pageSize?: number
  cursor?: string
  filters?: LogFilters  // NESTED structure for organized filtering
}

export class LogsRepository extends BaseRepository {
  private static instance: LogsRepository

  static getInstance(): LogsRepository {
    if (!this.instance) {
      this.instance = new LogsRepository()
    }
    return this.instance
  }

  /**
   * Insert a new log entry
   * CRITICAL: No ID generation - database handles via gen_random_uuid()
   */
  async createLog(log: Omit<LogInsert, 'id' | 'created_at'>): Promise<LogEntry> {
    const timer = permanentLogger.timing('repository.createLog')

    return this.execute('createLog', async (client) => {
      permanentLogger.breadcrumb('repository', 'Creating log entry', {
        log_level: log.log_level,
        category: log.category,
        timestamp: Date.now()
      })

      // NO ID field - let PostgreSQL gen_random_uuid() handle it
      const { data, error } = await client
        .from('permanent_logs')
        .insert(log)
        .select()
        .single()

      if (error) {
        // Don't use permanentLogger.captureError here - would cause infinite loop!
        console.error('Failed to create log entry:', error)
        throw error
      }

      if (!data) {
        throw new Error('Log creation failed - no data returned')
      }

      timer.stop()
      return data
    })
  }

  /**
   * Batch insert multiple log entries
   * Technical PM: More efficient for bulk operations
   */
  async createLogs(logs: Array<Omit<LogInsert, 'id' | 'created_at'>>): Promise<LogEntry[]> {
    const timer = permanentLogger.timing('repository.createLogs')

    return this.execute('createLogs', async (client) => {
      permanentLogger.breadcrumb('repository', 'Creating multiple log entries', {
        count: logs.length,
        timestamp: Date.now()
      })

      const { data, error } = await client
        .from('permanent_logs')
        .insert(logs)
        .select()

      if (error) {
        console.error('Failed to create log entries:', error)
        throw error
      }

      const entries = data || []
      timer.stop()
      return entries
    })
  }

  /**
   * Get paginated logs with filters
   *
   * EXPECTS: LogsQueryParams with NESTED filter structure
   * The service layer must transform flat API params to this format
   *
   * Technical PM: Supports complex filtering and pagination
   */
  async getPaginatedLogs(params: LogsQueryParams): Promise<{
    logs: LogEntry[]
    totalCount: number
    hasMore: boolean
    nextCursor?: string
  }> {
    const timer = permanentLogger.timing('repository.getPaginatedLogs')

    return this.execute('getPaginatedLogs', async (client) => {
      const page = params.page || 1
      const pageSize = Math.min(params.pageSize || 50, 200) // Max 200 per page
      const offset = (page - 1) * pageSize

      permanentLogger.breadcrumb('repository', 'Fetching paginated logs', {
        page,
        pageSize,
        filters: params.filters,
        timestamp: Date.now()
      })

      // Build query
      let query = client
        .from('permanent_logs')
        .select('*', { count: 'exact' })

      // Apply filters
      if (params.filters) {
        const { level, category, action, startDate, endDate, search } = params.filters

        // Level filter (supports array) - TYPE-SAFE!
        if (level) {
          const levels = Array.isArray(level) ? level : [level]
          query = query.in(typedColumn<LogsTable>('log_level'), levels)
        }

        // Category filter (supports array)
        if (category) {
          const categories = Array.isArray(category) ? category : [category]
          query = query.in('category', categories)
        }

        // Action filter (supports array)
        if (action) {
          const actions = Array.isArray(action) ? action : [action]
          query = query.in('action', actions)
        }

        // Date range filter
        if (startDate) {
          query = query.gte('created_at', startDate)
        }
        if (endDate) {
          query = query.lte('created_at', endDate)
        }

        // Search filter (searches message and data)
        if (search) {
          query = query.or(`message.ilike.%${search}%,data.ilike.%${search}%`)
        }
      }

      // Apply pagination and ordering
      query = query
        .order('created_at', { ascending: false })
        .range(offset, offset + pageSize - 1)

      const { data, error, count } = await query

      if (error) {
        console.error('Failed to fetch paginated logs:', error)
        throw error
      }

      const logs = data || []
      const totalCount = count || 0
      const hasMore = offset + logs.length < totalCount

      const duration = timer.stop()
      permanentLogger.breadcrumb('repository', 'Paginated logs fetched', {
        count: logs.length,
        totalCount,
        duration
      })

      return {
        logs,
        totalCount,
        hasMore,
        nextCursor: hasMore ? String(page + 1) : undefined
      }
    })
  }

  /**
   * Get log statistics
   * Technical PM: Provides overview of log distribution
   */
  async getLogStats(): Promise<{
    total: number
    byLevel: Record<string, number>
    byCategory: Record<string, number>
  }> {
    const timer = permanentLogger.timing('repository.getLogStats')

    return this.execute('getLogStats', async (client) => {
      permanentLogger.breadcrumb('repository', 'Fetching log statistics', {
        timestamp: Date.now()
      })

      // Get total count
      const { count: total, error: countError } = await client
        .from('permanent_logs')
        .select('*', { count: 'exact', head: true })

      if (countError) {
        console.error('Failed to get log count:', countError)
        throw countError
      }

      // Get level distribution - NOW TYPE-SAFE!
      // If we tried .select(typedColumn<LogsTable>('level')), TypeScript would error!
      const { data: levelData, error: levelError } = await client
        .from('permanent_logs')
        .select(typedColumn<LogsTable>('log_level'))

      if (levelError) {
        console.error('Failed to get level distribution:', levelError)
        throw levelError
      }

      // Calculate distributions
      const byLevel: Record<string, number> = {
        debug: 0,
        info: 0,
        warn: 0,
        error: 0,
        critical: 0
      }

      const byCategory: Record<string, number> = {}

      // Count levels (we'd need a separate query for categories)
      for (const log of levelData || []) {
        const level = log.log_level?.toLowerCase() || 'info'
        if (level in byLevel) {
          byLevel[level]++
        }
      }

      const duration = timer.stop()
      permanentLogger.breadcrumb('repository', 'Log statistics fetched', {
        total,
        duration
      })

      return {
        total: total || 0,
        byLevel,
        byCategory
      }
    })
  }

  /**
   * Delete ALL logs from database
   *
   * PURPOSE: Complete log cleanup for development/testing
   *
   * RESTORED FUNCTIONALITY: This was lost during repository migration
   * Previously worked before repository pattern was implemented
   * Now properly integrated with repository architecture
   *
   * SECURITY: Only available in development environment
   * API route checks NODE_ENV before calling
   *
   * WORKAROUND: Uses neq with impossible UUID to delete all
   * This is because Supabase doesn't allow DELETE without WHERE clause
   *
   * @returns Number of logs deleted
   * @throws Error if deletion fails or user lacks permissions (RLS)
   */
  async deleteAllLogs(): Promise<number> {
    const timer = permanentLogger.timing('repository.deleteAllLogs')

    return this.execute('deleteAllLogs', async (client) => {
      permanentLogger.breadcrumb('repository', 'Deleting all logs', {
        timestamp: Date.now()
      })

      // Get count before deletion for return value
      const { count, error: countError } = await client
        .from('permanent_logs')
        .select('*', { count: 'exact', head: true })

      if (countError) {
        console.error('Failed to count logs before deletion:', countError)
        throw countError
      }

      // Delete all logs
      // NOTE: neq with impossible UUID is a Supabase workaround
      // Supabase requires a WHERE clause, this effectively means "where id != impossible"
      // which matches all real records
      const { error: deleteError } = await client
        .from('permanent_logs')
        .delete()
        .neq('id', '00000000-0000-0000-0000-000000000000')

      if (deleteError) {
        console.error('Failed to delete all logs:', deleteError)
        throw deleteError
      }

      const deletedCount = count || 0

      timer.stop()
      permanentLogger.breadcrumb('repository', 'All logs deleted successfully', {
        deletedCount
      })

      return deletedCount
    })
  }

  /**
   * Delete old logs
   * Technical PM: For log rotation/cleanup
   */
  async deleteOldLogs(beforeDate: string): Promise<number> {
    const timer = permanentLogger.timing('repository.deleteOldLogs')

    return this.execute('deleteOldLogs', async (client) => {
      permanentLogger.breadcrumb('repository', 'Deleting old logs', {
        beforeDate,
        timestamp: Date.now()
      })

      // First get count of logs to delete
      const { count, error: countError } = await client
        .from('permanent_logs')
        .select('*', { count: 'exact', head: true })
        .lt('created_at', beforeDate)

      if (countError) {
        console.error('Failed to count old logs:', countError)
        throw countError
      }

      // Delete the logs
      const { error: deleteError } = await client
        .from('permanent_logs')
        .delete()
        .lt('created_at', beforeDate)

      if (deleteError) {
        console.error('Failed to delete old logs:', deleteError)
        throw deleteError
      }

      const deletedCount = count || 0

      timer.stop()
      permanentLogger.breadcrumb('repository', 'Old logs deleted', {
        deletedCount,
        beforeDate
      })

      return deletedCount
    })
  }

  /**
   * Get recent logs for a specific category
   * Technical PM: Quick access to recent activity
   */
  async getRecentLogsByCategory(
    category: string,
    limit: number = 10
  ): Promise<LogEntry[]> {
    const timer = permanentLogger.timing('repository.getRecentLogsByCategory')

    return this.execute('getRecentLogsByCategory', async (client) => {
      permanentLogger.breadcrumb('repository', 'Fetching recent logs by category', {
        category,
        limit,
        timestamp: Date.now()
      })

      const { data, error } = await client
        .from('permanent_logs')
        .select('*')
        .eq('category', category)
        .order('created_at', { ascending: false })
        .limit(limit)

      if (error) {
        console.error('Failed to fetch recent logs:', error)
        throw error
      }

      const logs = data || []
      timer.stop()
      return logs
    })
  }

  /**
   * Create a client error log entry
   *
   * CLAUDE.md Compliance:
   * - Part of Repository Pattern
   * - Uses BaseRepository error handling
   * - NO fallback data - errors bubble up
   * - Proper TypeScript types from database.types.ts
   *
   * This method is specifically for client-side errors reported
   * via the /api/logs/client-error endpoint. It uses the server's
   * auth context to avoid RLS issues.
   */
  async createClientError(logData: {
    log_level: 'error'
    category: string
    message: string
    data?: any
    stack?: string | null
    breadcrumbs?: any
    environment?: string
  }): Promise<LogEntry> {
    const timer = permanentLogger.timing('repository.createClientError')

    return this.execute('createClientError', async (client) => {
      permanentLogger.breadcrumb('repository', 'Creating client error log', {
        category: logData.category,
        timestamp: Date.now()
      })

      // Build the insert object with proper types
      // UUID is generated by PostgreSQL with gen_random_uuid() - CLAUDE.md compliant
      const insertData: LogInsert = {
        log_level: logData.log_level,
        category: logData.category,
        message: logData.message,
        data: logData.data || null,
        stack: logData.stack || null,
        breadcrumbs: logData.breadcrumbs || null,
        environment: logData.environment || process.env.NODE_ENV || 'development',
        log_timestamp: new Date().toISOString(),
        // Don't include id - let PostgreSQL generate it
        // user_id will be captured from auth context if available
      }

      const { data, error } = await client
        .from('permanent_logs')
        .insert(insertData)
        .select()
        .single()

      if (error) {
        // CLAUDE.md: Use captureError, never swallow errors
        permanentLogger.captureError('LOGS_REPOSITORY', error as Error, {
          operation: 'createClientError',
          category: logData.category
        })
        throw error
      }

      if (!data) {
        // NO fallback data - throw real error
        throw new Error('Failed to create client error log: No data returned')
      }

      timer.stop()
      permanentLogger.info('LOGS_REPOSITORY', 'Client error logged successfully', {
        logId: data.id,
        category: data.category
      })

      return data
    })
  }
}